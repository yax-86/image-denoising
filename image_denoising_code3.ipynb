{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Libraries"
      ],
      "metadata": {
        "id": "ZyQ2R22mrGCd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "K-fSqiqars7i"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from math import log10,sqrt\n",
        "from glob import glob\n",
        "import cv2\n",
        "import os\n",
        "import keras\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loading"
      ],
      "metadata": {
        "id": "HAfPOgn6rLoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16"
      ],
      "metadata": {
        "id": "IkB4iLLWlm51"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_preprocess2(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(images=img, size=[400, 400])\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "def data_preprocess1(images):\n",
        "    img = tf.data.Dataset.from_tensor_slices((images))\n",
        "    img = img.map(data_preprocess2, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    img = img.batch(batch_size, drop_remainder=True)\n",
        "    return img"
      ],
      "metadata": {
        "id": "dotoZluXkuc5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = sorted(glob(\"/content/drive/MyDrive/lol_dataset/our485/low/*\"))[:420]\n",
        "val_images = sorted(glob(\"/content/drive/MyDrive/lol_dataset/our485/low/*\"))[420:]\n",
        "test_images = sorted(glob(\"/content/drive/MyDrive/lol_dataset/eval15/low/*\"))\n",
        "\n",
        "\n",
        "train_dataset = data_preprocess1(train_images)\n",
        "val_dataset = data_preprocess1(val_images)\n",
        "batch_size=1\n",
        "test_dataset = data_preprocess1(test_images)"
      ],
      "metadata": {
        "id": "ViGf6O4z69wT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "Sf1cIZuLrPC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_dce_net():\n",
        "    input = keras.Input(shape=[None, None, 3])\n",
        "    c0 = layers.Conv2D(16, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\")(input)\n",
        "    c1 = layers.Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\")(c0)\n",
        "    c2 = layers.Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\")(c1)\n",
        "    c3 = layers.Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\")(c2)\n",
        "    c4 = layers.Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\")(c3)\n",
        "    con1 = layers.Concatenate(axis=-1)([c4, c3])\n",
        "    c5 = layers.Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\")(con1)\n",
        "    con2 = layers.Concatenate(axis=-1)([c5, c2])\n",
        "    c6 = layers.Conv2D(32, (3, 3), strides=(1, 1), activation=\"relu\", padding=\"same\")(con2)\n",
        "    con3 = layers.Concatenate(axis=-1)([c6, c1])\n",
        "    output = layers.Conv2D(24, (3, 3), strides=(1, 1), activation=\"tanh\", padding=\"same\")(con3)\n",
        "    return keras.Model(inputs=input, outputs=output)"
      ],
      "metadata": {
        "id": "FssDtWqYmF4n"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Losses"
      ],
      "metadata": {
        "id": "eY2-YMl2rRdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ConstancyLoss(image_tensor):\n",
        "    # Compute the mean RGB values across the height and width dimensions\n",
        "    mean_colors = tf.reduce_mean(image_tensor, axis=(1, 2), keepdims=True)\n",
        "\n",
        "    # Extract the mean values for each channel\n",
        "    mean_r, mean_g, mean_b = (\n",
        "        mean_colors[:, :, :, 0],\n",
        "        mean_colors[:, :, :, 1],\n",
        "        mean_colors[:, :, :, 2],\n",
        "    )\n",
        "\n",
        "    # Calculate the squared differences between the mean values of each pair of channels\n",
        "    diff_rg = tf.square(mean_r - mean_g)\n",
        "    diff_rb = tf.square(mean_r - mean_b)\n",
        "    diff_gb = tf.square(mean_b - mean_g)\n",
        "\n",
        "    # Return the combined loss as the square root of the sum of the squared differences\n",
        "    return tf.sqrt(diff_rg + diff_rb + diff_gb)"
      ],
      "metadata": {
        "id": "dru0peQ1mG4h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ExposureLoss(image_tensor, target_mean_value=0.6):\n",
        "    # Compute the mean intensity value across the RGB channels\n",
        "    mean_intensity = tf.reduce_mean(image_tensor, axis=3, keepdims=True)\n",
        "\n",
        "    # Perform average pooling with a kernel size and stride of 16\n",
        "    pooled_mean_intensity = tf.nn.avg_pool2d(mean_intensity, ksize=16, strides=16, padding=\"VALID\")\n",
        "\n",
        "    # Calculate the exposure loss as the mean squared difference from the target mean value\n",
        "    ExposureLoss_value = tf.reduce_mean(tf.square(pooled_mean_intensity - target_mean_value))\n",
        "\n",
        "    return ExposureLoss_value"
      ],
      "metadata": {
        "id": "ZJequXRSr1Gy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SmoothnessLoss(image_tensor):\n",
        "    batch_size = tf.shape(image_tensor)[0]\n",
        "    height = tf.shape(image_tensor)[1]\n",
        "    width = tf.shape(image_tensor)[2]\n",
        "    channels = tf.shape(image_tensor)[3]\n",
        "\n",
        "    # Calculate the total number of horizontal and vertical differences\n",
        "    total_horizontal = (width - 1) * channels\n",
        "    total_vertical = width * (channels - 1)\n",
        "\n",
        "    # Compute the horizontal and vertical total variation\n",
        "    horizontal_variation = tf.reduce_sum(tf.square(image_tensor[:, 1:, :, :] - image_tensor[:, :-1, :, :]))\n",
        "    vertical_variation = tf.reduce_sum(tf.square(image_tensor[:, :, 1:, :] - image_tensor[:, :, :-1, :]))\n",
        "\n",
        "    # Cast to float32 for division\n",
        "    total_horizontal = tf.cast(total_horizontal, dtype=tf.float32)\n",
        "    total_vertical = tf.cast(total_vertical, dtype=tf.float32)\n",
        "    batch_size = tf.cast(batch_size, dtype=tf.float32)\n",
        "\n",
        "    # Return the average smoothness loss per batch\n",
        "    return 2 * (horizontal_variation / total_horizontal + vertical_variation / total_vertical) / batch_size"
      ],
      "metadata": {
        "id": "AwxtZoMnsHY_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SpatialConsistencyLoss(keras.losses.Loss):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(reduction=\"none\")\n",
        "        self.kernels = {\n",
        "            \"left\": tf.constant([[[[0, 0, 0]], [[-1, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32),\n",
        "            \"right\": tf.constant([[[[0, 0, 0]], [[0, 1, -1]], [[0, 0, 0]]]], dtype=tf.float32),\n",
        "            \"up\": tf.constant([[[[0, -1, 0]], [[0, 1, 0]], [[0, 0, 0]]]], dtype=tf.float32),\n",
        "            \"down\": tf.constant([[[[0, 0, 0]], [[0, 1, 0]], [[0, -1, 0]]]], dtype=tf.float32)\n",
        "        }\n",
        "\n",
        "    def call(self, true, pred):\n",
        "        mean_true = tf.reduce_mean(true, axis=3, keepdims=True)\n",
        "        mean_pred = tf.reduce_mean(pred, axis=3, keepdims=True)\n",
        "\n",
        "        pool_true = tf.nn.avg_pool2d(mean_true, ksize=4, strides=4, padding=\"VALID\")\n",
        "        pool_pred = tf.nn.avg_pool2d(mean_pred, ksize=4, strides=4, padding=\"VALID\")\n",
        "\n",
        "        diffs = []\n",
        "        for direction, kernel in self.kernels.items():\n",
        "            diff_true = tf.nn.conv2d(pool_true, kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "            diff_pred = tf.nn.conv2d(pool_pred, kernel, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
        "            diffs.append(tf.square(diff_true - diff_pred))\n",
        "\n",
        "        return tf.add_n(diffs)"
      ],
      "metadata": {
        "id": "WBOj11NJsZf6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ZeroDCE(keras.Model):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.dce_model = build_dce_net()\n",
        "\n",
        "    def compile(self, learning_rate, **kwargs):\n",
        "        super().compile(**kwargs)\n",
        "        self.optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "        self.spatial_constancy_loss = SpatialConsistencyLoss(reduction=\"none\")\n",
        "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.SmoothnessLoss_tracker = keras.metrics.Mean(\n",
        "            name=\"SmoothnessLoss\"\n",
        "        )\n",
        "        self.spatial_constancy_loss_tracker = keras.metrics.Mean(\n",
        "            name=\"spatial_constancy_loss\"\n",
        "        )\n",
        "        self.ConstancyLoss_tracker = keras.metrics.Mean(\n",
        "            name=\"ConstancyLoss\"\n",
        "        )\n",
        "        self.ExposureLoss_tracker = keras.metrics.Mean(name=\"ExposureLoss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.SmoothnessLoss_tracker,\n",
        "            self.spatial_constancy_loss_tracker,\n",
        "            self.ConstancyLoss_tracker,\n",
        "            self.ExposureLoss_tracker,\n",
        "        ]\n",
        "\n",
        "    def get_enhanced_image(self, data, output):\n",
        "        r1 = output[:, :, :, :3]\n",
        "        r2 = output[:, :, :, 3:6]\n",
        "        r3 = output[:, :, :, 6:9]\n",
        "        r4 = output[:, :, :, 9:12]\n",
        "        r5 = output[:, :, :, 12:15]\n",
        "        r6 = output[:, :, :, 15:18]\n",
        "        r7 = output[:, :, :, 18:21]\n",
        "        r8 = output[:, :, :, 21:24]\n",
        "        x = data + r1 * (tf.square(data) - data)\n",
        "        x = x + r2 * (tf.square(x) - x)\n",
        "        x = x + r3 * (tf.square(x) - x)\n",
        "        enhanced_image = x + r4 * (tf.square(x) - x)\n",
        "        x = enhanced_image + r5 * (tf.square(enhanced_image) - enhanced_image)\n",
        "        x = x + r6 * (tf.square(x) - x)\n",
        "        x = x + r7 * (tf.square(x) - x)\n",
        "        enhanced_image = x + r8 * (tf.square(x) - x)\n",
        "        return enhanced_image\n",
        "\n",
        "    def call(self, data):\n",
        "        dce_net_output = self.dce_model(data)\n",
        "        return self.get_enhanced_image(data, dce_net_output)\n",
        "\n",
        "    def compute_losses(self, data, output):\n",
        "        enhanced_image = self.get_enhanced_image(data, output)\n",
        "        loss_illumination = 200 * SmoothnessLoss(output)\n",
        "        loss_spatial_constancy = tf.reduce_mean(\n",
        "            self.spatial_constancy_loss(enhanced_image, data)\n",
        "        )\n",
        "        loss_color_constancy = 5 * tf.reduce_mean(ConstancyLoss(enhanced_image))\n",
        "        loss_exposure = 10 * tf.reduce_mean(ExposureLoss(enhanced_image))\n",
        "        total_loss = (\n",
        "            loss_illumination\n",
        "            + loss_spatial_constancy\n",
        "            + loss_color_constancy\n",
        "            + loss_exposure\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"total_loss\": total_loss,\n",
        "            \"SmoothnessLoss\": loss_illumination,\n",
        "            \"spatial_constancy_loss\": loss_spatial_constancy,\n",
        "            \"ConstancyLoss\": loss_color_constancy,\n",
        "            \"ExposureLoss\": loss_exposure,\n",
        "        }\n",
        "\n",
        "    def train_step(self, data):\n",
        "        with tf.GradientTape() as tape:\n",
        "            output = self.dce_model(data)\n",
        "            losses = self.compute_losses(data, output)\n",
        "\n",
        "        gradients = tape.gradient(\n",
        "            losses[\"total_loss\"], self.dce_model.trainable_weights\n",
        "        )\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.dce_model.trainable_weights))\n",
        "\n",
        "        self.total_loss_tracker.update_state(losses[\"total_loss\"])\n",
        "        self.SmoothnessLoss_tracker.update_state(\n",
        "            losses[\"SmoothnessLoss\"]\n",
        "        )\n",
        "        self.spatial_constancy_loss_tracker.update_state(\n",
        "            losses[\"spatial_constancy_loss\"]\n",
        "        )\n",
        "        self.ConstancyLoss_tracker.update_state(losses[\"ConstancyLoss\"])\n",
        "        self.ExposureLoss_tracker.update_state(losses[\"ExposureLoss\"])\n",
        "\n",
        "        return {metric.name: metric.result() for metric in self.metrics}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        output = self.dce_model(data)\n",
        "        losses = self.compute_losses(data, output)\n",
        "\n",
        "        self.total_loss_tracker.update_state(losses[\"total_loss\"])\n",
        "        self.SmoothnessLoss_tracker.update_state(\n",
        "            losses[\"SmoothnessLoss\"]\n",
        "        )\n",
        "        self.spatial_constancy_loss_tracker.update_state(\n",
        "            losses[\"spatial_constancy_loss\"]\n",
        "        )\n",
        "        self.ConstancyLoss_tracker.update_state(losses[\"ConstancyLoss\"])\n",
        "        self.ExposureLoss_tracker.update_state(losses[\"ExposureLoss\"])\n",
        "\n",
        "        return {metric.name: metric.result() for metric in self.metrics}\n",
        "\n",
        "    def save_weights(self, filepath, overwrite=True, save_format=None, options=None):\n",
        "\n",
        "        self.dce_model.save_weights(\n",
        "            filepath,\n",
        "            overwrite=overwrite,\n",
        "            save_format=save_format,\n",
        "            options=options,\n",
        "        )\n",
        "\n",
        "    def load_weights(self, filepath, by_name=False, skip_mismatch=False, options=None):\n",
        "\n",
        "        self.dce_model.load_weights(\n",
        "            filepath=filepath,\n",
        "            by_name=by_name,\n",
        "            skip_mismatch=skip_mismatch,\n",
        "            options=options,\n",
        "        )"
      ],
      "metadata": {
        "id": "NsrBYpxLsuO2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ZeroDCE()\n",
        "model.compile(learning_rate=1e-4)\n",
        "history = model.fit(train_dataset, validation_data=val_dataset, epochs=100)\n",
        "model.save('/content/drive/MyDrive/lol_dataset/sphgetti_net.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDeURY4ltkft",
        "outputId": "43044109-23e4-41d8-eeac-02e306b294c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "21/21 [==============================] - 22s 813ms/step - total_loss: 4.1571 - SmoothnessLoss: 1.1280 - spatial_constancy_loss: 1.3558e-05 - ConstancyLoss: 0.1024 - ExposureLoss: 2.9267 - val_total_loss: 4.1833 - val_SmoothnessLoss: 1.0368 - val_spatial_constancy_loss: 8.6749e-06 - val_ConstancyLoss: 0.1050 - val_ExposureLoss: 3.0415\n",
            "Epoch 2/100\n",
            "21/21 [==============================] - 16s 734ms/step - total_loss: 3.5808 - SmoothnessLoss: 0.5570 - spatial_constancy_loss: 1.8078e-05 - ConstancyLoss: 0.1018 - ExposureLoss: 2.9219 - val_total_loss: 3.7405 - val_SmoothnessLoss: 0.5974 - val_spatial_constancy_loss: 1.1162e-05 - val_ConstancyLoss: 0.1059 - val_ExposureLoss: 3.0373\n",
            "Epoch 3/100\n",
            "21/21 [==============================] - 15s 712ms/step - total_loss: 3.3464 - SmoothnessLoss: 0.3272 - spatial_constancy_loss: 2.1970e-05 - ConstancyLoss: 0.1024 - ExposureLoss: 2.9167 - val_total_loss: 3.5288 - val_SmoothnessLoss: 0.3900 - val_spatial_constancy_loss: 1.5377e-05 - val_ConstancyLoss: 0.1069 - val_ExposureLoss: 3.0320\n",
            "Epoch 4/100\n",
            "21/21 [==============================] - 15s 727ms/step - total_loss: 3.2318 - SmoothnessLoss: 0.2186 - spatial_constancy_loss: 3.1032e-05 - ConstancyLoss: 0.1032 - ExposureLoss: 2.9100 - val_total_loss: 3.4122 - val_SmoothnessLoss: 0.2785 - val_spatial_constancy_loss: 2.2821e-05 - val_ConstancyLoss: 0.1078 - val_ExposureLoss: 3.0259\n",
            "Epoch 5/100\n",
            "21/21 [==============================] - 16s 746ms/step - total_loss: 3.1613 - SmoothnessLoss: 0.1544 - spatial_constancy_loss: 4.3501e-05 - ConstancyLoss: 0.1039 - ExposureLoss: 2.9029 - val_total_loss: 3.3359 - val_SmoothnessLoss: 0.2076 - val_spatial_constancy_loss: 3.2317e-05 - val_ConstancyLoss: 0.1090 - val_ExposureLoss: 3.0192\n",
            "Epoch 6/100\n",
            "21/21 [==============================] - 16s 761ms/step - total_loss: 3.1125 - SmoothnessLoss: 0.1128 - spatial_constancy_loss: 5.9612e-05 - ConstancyLoss: 0.1048 - ExposureLoss: 2.8948 - val_total_loss: 3.2845 - val_SmoothnessLoss: 0.1627 - val_spatial_constancy_loss: 4.6542e-05 - val_ConstancyLoss: 0.1108 - val_ExposureLoss: 3.0110\n",
            "Epoch 7/100\n",
            "21/21 [==============================] - 16s 751ms/step - total_loss: 3.0763 - SmoothnessLoss: 0.0859 - spatial_constancy_loss: 8.5171e-05 - ConstancyLoss: 0.1062 - ExposureLoss: 2.8842 - val_total_loss: 3.2460 - val_SmoothnessLoss: 0.1326 - val_spatial_constancy_loss: 7.0509e-05 - val_ConstancyLoss: 0.1134 - val_ExposureLoss: 2.9999\n",
            "Epoch 8/100\n",
            "21/21 [==============================] - 16s 755ms/step - total_loss: 3.0467 - SmoothnessLoss: 0.0683 - spatial_constancy_loss: 1.2667e-04 - ConstancyLoss: 0.1080 - ExposureLoss: 2.8703 - val_total_loss: 3.2142 - val_SmoothnessLoss: 0.1117 - val_spatial_constancy_loss: 1.0850e-04 - val_ConstancyLoss: 0.1165 - val_ExposureLoss: 2.9859\n",
            "Epoch 9/100\n",
            "21/21 [==============================] - 16s 736ms/step - total_loss: 3.0212 - SmoothnessLoss: 0.0570 - spatial_constancy_loss: 1.8754e-04 - ConstancyLoss: 0.1102 - ExposureLoss: 2.8539 - val_total_loss: 3.1851 - val_SmoothnessLoss: 0.0948 - val_spatial_constancy_loss: 1.6193e-04 - val_ConstancyLoss: 0.1199 - val_ExposureLoss: 2.9702\n",
            "Epoch 10/100\n",
            "21/21 [==============================] - 16s 761ms/step - total_loss: 2.9977 - SmoothnessLoss: 0.0487 - spatial_constancy_loss: 2.6850e-04 - ConstancyLoss: 0.1128 - ExposureLoss: 2.8359 - val_total_loss: 3.1548 - val_SmoothnessLoss: 0.0777 - val_spatial_constancy_loss: 2.3206e-04 - val_ConstancyLoss: 0.1238 - val_ExposureLoss: 2.9530\n",
            "Epoch 11/100\n",
            "19/21 [==========================>...] - ETA: 1s - total_loss: 2.9948 - SmoothnessLoss: 0.0416 - spatial_constancy_loss: 3.6010e-04 - ConstancyLoss: 0.1172 - ExposureLoss: 2.8357"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model = load_model('/content/drive/MyDrive/lol_dataset/sphgetti_net.h5')"
      ],
      "metadata": {
        "id": "V_PtDn3yCqrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred=model.predict(test_dataset)"
      ],
      "metadata": {
        "id": "IReY2fgEuZg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test_images = sorted(glob(\"/content/drive/MyDrive/lol_dataset/eval15/high/*\"))\n",
        "y_test=[]\n",
        "for file in y_test_images:\n",
        "  img = tf.io.read_file(file)\n",
        "  img = tf.image.decode_png(img, channels=3)\n",
        "  img = tf.image.resize(images=img, size=[400, 400])\n",
        "  img = img / 255.0\n",
        "  y_test.append(img)"
      ],
      "metadata": {
        "id": "6uRsI0Dc3var"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def PSNR(original, compressed):\n",
        "    mse = np.mean((original - compressed) ** 2)\n",
        "    if(mse == 0):\n",
        "        return 100\n",
        "    max_pixel = 1.0\n",
        "    psnr = 20 * log10(max_pixel / sqrt(mse))\n",
        "    return psnr"
      ],
      "metadata": {
        "id": "palVhoC25M_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test=np.array(y_test)"
      ],
      "metadata": {
        "id": "kwRGZfea73mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PSNR(y_test,pred)"
      ],
      "metadata": {
        "id": "lbs1sL544S6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "pakaRSjP5XJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(y_test,pred)"
      ],
      "metadata": {
        "id": "VGxecy9i50ZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(image01,image02):\n",
        "    error= np.sum((image01.astype(\"float\")- image02.astype(\"float\"))**2)\n",
        "    error= error/float(image01.shape[0]*image02.shape[1])\n",
        "    return error"
      ],
      "metadata": {
        "id": "CW1gdXD053vb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(image01,image02):\n",
        "    error= np.sum(abs(image01.astype(\"float\")- image02.astype(\"float\")))\n",
        "    error= error/float(image01.shape[0]*image02.shape[1])\n",
        "    return error"
      ],
      "metadata": {
        "id": "BvzxYxVZ8ILN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_err=[]\n",
        "mae_err=[]\n",
        "for i in range(len(y_test)):\n",
        "  mse_err.append(mse(y_test[i],pred[i]))\n",
        "  mae_err.append(mae(y_test[i],pred[i]))\n",
        "print(np.mean(mse_err))\n",
        "print(np.mean(mae_err))"
      ],
      "metadata": {
        "id": "id27lKwb6GL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Z02DMrqJ7wLq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}